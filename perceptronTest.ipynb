{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lotus-owl/kdta_ROS2/blob/main/perceptronTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 선형 분류\n"
      ],
      "metadata": {
        "id": "PahsoU1Cggye"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAqCAHiagBq4"
      },
      "outputs": [],
      "source": [
        "def AND_gate(x1, x2):\n",
        "    w1=0.5\n",
        "    w2=0.5\n",
        "    b=-0.7\n",
        "    result = x1*w1 + x2*w2 + b\n",
        "    if result <= 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AND_gate(0, 0), AND_gate(0, 1), AND_gate(1, 0), AND_gate(1, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRAj3lHWgJF4",
        "outputId": "40431afc-72e6-42b2-b635-c8a67a86a9c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0, 0, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def NAND_gate(x1, x2):\n",
        "    w1=-0.5\n",
        "    w2=-0.5\n",
        "    b=0.7\n",
        "    result = x1*w1 + x2*w2 + b\n",
        "    if result <= 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ],
      "metadata": {
        "id": "pzvnMS8FgK5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NAND_gate(0, 0), NAND_gate(0, 1), NAND_gate(1, 0), NAND_gate(1, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyeAuInxgPRU",
        "outputId": "64e4df7a-0f6e-4f10-b4e9-ea5357090672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1, 1, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def OR_gate(x1, x2):\n",
        "    w1=0.6\n",
        "    w2=0.6\n",
        "    b=-0.5\n",
        "    result = x1*w1 + x2*w2 + b\n",
        "    if result <= 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ],
      "metadata": {
        "id": "1lzPDaAIgRNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OR_gate(0, 0), OR_gate(0, 1), OR_gate(1, 0), OR_gate(1, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mQc26ZvgUlo",
        "outputId": "24bf70e9-da06-4ac6-ef4b-5591c93f613e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1, 1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 단층 퍼셉트론"
      ],
      "metadata": {
        "id": "mRgaDGDLgdEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "76mhtuylgtbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "id": "zAGJKb1qgtRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
      ],
      "metadata": {
        "id": "PdhcicEqgtLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear = nn.Linear(2, 1, bias=True)\n",
        "sigmoid = nn.Sigmoid()\n",
        "model = nn.Sequential(linear, sigmoid).to(device)\n"
      ],
      "metadata": {
        "id": "zlfpLZSqg7wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 비용 함수와 옵티마이저 정의\n",
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n"
      ],
      "metadata": {
        "id": "3n5VcI84g83N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(10001):\n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = model(X)\n",
        "\n",
        "    # 비용 함수\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 100 == 0: # 100번째 에포크마다 비용 출력\n",
        "        print(step, cost.item())\n"
      ],
      "metadata": {
        "id": "GJ1zE_kxg8pF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e01465-7b1a-4927-9587-f054ab6d6feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.7273973822593689\n",
            "100 0.6931476593017578\n",
            "200 0.6931471824645996\n",
            "300 0.6931471824645996\n",
            "400 0.6931471824645996\n",
            "500 0.6931471824645996\n",
            "600 0.6931471824645996\n",
            "700 0.6931471824645996\n",
            "800 0.6931471824645996\n",
            "900 0.6931471824645996\n",
            "1000 0.6931471824645996\n",
            "1100 0.6931471824645996\n",
            "1200 0.6931471824645996\n",
            "1300 0.6931471824645996\n",
            "1400 0.6931471824645996\n",
            "1500 0.6931471824645996\n",
            "1600 0.6931471824645996\n",
            "1700 0.6931471824645996\n",
            "1800 0.6931471824645996\n",
            "1900 0.6931471824645996\n",
            "2000 0.6931471824645996\n",
            "2100 0.6931471824645996\n",
            "2200 0.6931471824645996\n",
            "2300 0.6931471824645996\n",
            "2400 0.6931471824645996\n",
            "2500 0.6931471824645996\n",
            "2600 0.6931471824645996\n",
            "2700 0.6931471824645996\n",
            "2800 0.6931471824645996\n",
            "2900 0.6931471824645996\n",
            "3000 0.6931471824645996\n",
            "3100 0.6931471824645996\n",
            "3200 0.6931471824645996\n",
            "3300 0.6931471824645996\n",
            "3400 0.6931471824645996\n",
            "3500 0.6931471824645996\n",
            "3600 0.6931471824645996\n",
            "3700 0.6931471824645996\n",
            "3800 0.6931471824645996\n",
            "3900 0.6931471824645996\n",
            "4000 0.6931471824645996\n",
            "4100 0.6931471824645996\n",
            "4200 0.6931471824645996\n",
            "4300 0.6931471824645996\n",
            "4400 0.6931471824645996\n",
            "4500 0.6931471824645996\n",
            "4600 0.6931471824645996\n",
            "4700 0.6931471824645996\n",
            "4800 0.6931471824645996\n",
            "4900 0.6931471824645996\n",
            "5000 0.6931471824645996\n",
            "5100 0.6931471824645996\n",
            "5200 0.6931471824645996\n",
            "5300 0.6931471824645996\n",
            "5400 0.6931471824645996\n",
            "5500 0.6931471824645996\n",
            "5600 0.6931471824645996\n",
            "5700 0.6931471824645996\n",
            "5800 0.6931471824645996\n",
            "5900 0.6931471824645996\n",
            "6000 0.6931471824645996\n",
            "6100 0.6931471824645996\n",
            "6200 0.6931471824645996\n",
            "6300 0.6931471824645996\n",
            "6400 0.6931471824645996\n",
            "6500 0.6931471824645996\n",
            "6600 0.6931471824645996\n",
            "6700 0.6931471824645996\n",
            "6800 0.6931471824645996\n",
            "6900 0.6931471824645996\n",
            "7000 0.6931471824645996\n",
            "7100 0.6931471824645996\n",
            "7200 0.6931471824645996\n",
            "7300 0.6931471824645996\n",
            "7400 0.6931471824645996\n",
            "7500 0.6931471824645996\n",
            "7600 0.6931471824645996\n",
            "7700 0.6931471824645996\n",
            "7800 0.6931471824645996\n",
            "7900 0.6931471824645996\n",
            "8000 0.6931471824645996\n",
            "8100 0.6931471824645996\n",
            "8200 0.6931471824645996\n",
            "8300 0.6931471824645996\n",
            "8400 0.6931471824645996\n",
            "8500 0.6931471824645996\n",
            "8600 0.6931471824645996\n",
            "8700 0.6931471824645996\n",
            "8800 0.6931471824645996\n",
            "8900 0.6931471824645996\n",
            "9000 0.6931471824645996\n",
            "9100 0.6931471824645996\n",
            "9200 0.6931471824645996\n",
            "9300 0.6931471824645996\n",
            "9400 0.6931471824645996\n",
            "9500 0.6931471824645996\n",
            "9600 0.6931471824645996\n",
            "9700 0.6931471824645996\n",
            "9800 0.6931471824645996\n",
            "9900 0.6931471824645996\n",
            "10000 0.6931471824645996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    hypothesis = model(X)\n",
        "    predicted = (hypothesis > 0.5).float()\n",
        "    accuracy = (predicted == Y).float().mean()\n",
        "    print('모델의 출력값(Hypothesis): ', hypothesis.detach().cpu().numpy())\n",
        "    print('모델의 예측값(Predicted): ', predicted.detach().cpu().numpy())\n",
        "    print('실제값(Y): ', Y.cpu().numpy())\n",
        "    print('정확도(Accuracy): ', accuracy.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNGbut_NgWB_",
        "outputId": "6ec0e5fe-678e-4a62-e217-ef4b5762bdce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델의 출력값(Hypothesis):  [[0.5]\n",
            " [0.5]\n",
            " [0.5]\n",
            " [0.5]]\n",
            "모델의 예측값(Predicted):  [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "실제값(Y):  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "정확도(Accuracy):  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9M7nEuivhkTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 다층 퍼셉트론\n"
      ],
      "metadata": {
        "id": "o_wB63fliOUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear = nn.Linear(2, 1, bias=True)\n",
        "sigmoid = nn.Sigmoid()\n",
        "model = nn.Sequential(\n",
        "          nn.Linear(2, 10, bias=True), # input_layer = 2, hidden_layer1 = 10\n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10\n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(10, 10, bias=True), # hidden_layer2 = 10, hidden_layer3 = 10\n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer = 1\n",
        "          nn.Sigmoid()\n",
        "          ).to(device)\n"
      ],
      "metadata": {
        "id": "lsyw600ViRZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)  # modified learning rate from 0.1 to 1\n"
      ],
      "metadata": {
        "id": "tS9UESlCiReh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10001):\n",
        "    optimizer.zero_grad()\n",
        "    # forward 연산\n",
        "    hypothesis = model(X)\n",
        "\n",
        "    # 비용 함수\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100의 배수에 해당되는 에포크마다 비용을 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print(epoch, cost.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdPdqyoiiRb1",
        "outputId": "86403820-4726-468e-e5cd-5dcf401bd4bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.6978083848953247\n",
            "100 0.693110466003418\n",
            "200 0.6931020021438599\n",
            "300 0.6930921673774719\n",
            "400 0.6930808424949646\n",
            "500 0.6930676698684692\n",
            "600 0.6930519938468933\n",
            "700 0.6930330395698547\n",
            "800 0.6930098533630371\n",
            "900 0.6929808855056763\n",
            "1000 0.6929439902305603\n",
            "1100 0.6928958296775818\n",
            "1200 0.6928311586380005\n",
            "1300 0.6927415132522583\n",
            "1400 0.6926121115684509\n",
            "1500 0.692415714263916\n",
            "1600 0.6920979619026184\n",
            "1700 0.6915386915206909\n",
            "1800 0.6904336214065552\n",
            "1900 0.6878381371498108\n",
            "2000 0.6797102689743042\n",
            "2100 0.6408315300941467\n",
            "2200 0.5488753914833069\n",
            "2300 0.5083183646202087\n",
            "2400 0.48752066493034363\n",
            "2500 0.49485543370246887\n",
            "2600 0.020168201997876167\n",
            "2700 0.007714718580245972\n",
            "2800 0.004507092759013176\n",
            "2900 0.0031063624192029238\n",
            "3000 0.0023384764790534973\n",
            "3100 0.0018596602603793144\n",
            "3200 0.0015350301982834935\n",
            "3300 0.0013017852324992418\n",
            "3400 0.001126720104366541\n",
            "3500 0.0009909045184031129\n",
            "3600 0.0008827366982586682\n",
            "3700 0.0007946990663185716\n",
            "3800 0.0007217366364784539\n",
            "3900 0.0006604286027140915\n",
            "4000 0.0006082049803808331\n",
            "4100 0.0005631978856399655\n",
            "4200 0.0005240626051090658\n",
            "4300 0.0004897536127828062\n",
            "4400 0.0004594501806423068\n",
            "4500 0.00043245963752269745\n",
            "4600 0.0004083555832039565\n",
            "4700 0.0003866034676320851\n",
            "4800 0.00036699665361084044\n",
            "4900 0.0003491872630547732\n",
            "5000 0.0003329078608658165\n",
            "5100 0.0003180014027748257\n",
            "5200 0.0003043248725589365\n",
            "5300 0.00029174407245591283\n",
            "5400 0.00028006741194985807\n",
            "5500 0.0002692377311177552\n",
            "5600 0.00025921568158082664\n",
            "5700 0.0002498492249287665\n",
            "5800 0.00024114095140248537\n",
            "5900 0.00023296249855775386\n",
            "6000 0.00022531728609465063\n",
            "6100 0.0002180823212256655\n",
            "6200 0.0002112997171934694\n",
            "6300 0.0002049242175417021\n",
            "6400 0.00019891245756298304\n",
            "6500 0.0001931923470692709\n",
            "6600 0.00018778277444653213\n",
            "6700 0.00018267311679665\n",
            "6800 0.00017782532086130232\n",
            "6900 0.0001732009113766253\n",
            "7000 0.00016880896873772144\n",
            "7100 0.00016461240011267364\n",
            "7200 0.00016061706992331892\n",
            "7300 0.00015681992226745933\n",
            "7400 0.0001531545422039926\n",
            "7500 0.00014967807510402054\n",
            "7600 0.00014635513070970774\n",
            "7700 0.00014312165149021894\n",
            "7800 0.00014006438141223043\n",
            "7900 0.00013712025247514248\n",
            "8000 0.0001343029725831002\n",
            "8100 0.00013157710782252252\n",
            "8200 0.00012895559484604746\n",
            "8300 0.0001264343736693263\n",
            "8400 0.0001240131532540545\n",
            "8500 0.00012165990483481437\n",
            "8600 0.00011940162221435457\n",
            "8700 0.00011723737407010049\n",
            "8800 0.00011513533536344767\n",
            "8900 0.00011309432738926262\n",
            "9000 0.00011114202789030969\n",
            "9100 0.00010921645298367366\n",
            "9200 0.00010740791185526177\n",
            "9300 0.00010559494694462046\n",
            "9400 0.00010389537055743858\n",
            "9500 0.00010221797128906474\n",
            "9600 0.00010059317719424143\n",
            "9700 9.898901043925434e-05\n",
            "9800 9.746472642291337e-05\n",
            "9900 9.598975884728134e-05\n",
            "10000 9.453295933781192e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    hypothesis = model(X)\n",
        "    predicted = (hypothesis > 0.5).float()\n",
        "    accuracy = (predicted == Y).float().mean()\n",
        "    print('모델의 출력값(Hypothesis): \\n', hypothesis.detach().cpu().numpy())\n",
        "    print('모델의 예측값(Predicted): \\n', predicted.detach().cpu().numpy())\n",
        "    print('실제값(Y): \\n', Y.cpu().numpy())\n",
        "    print('정확도(Accuracy): \\n', accuracy.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOgHS2nCicZU",
        "outputId": "608af6a0-9d53-4747-91f8-79b3f1ed7681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델의 출력값(Hypothesis): \n",
            " [[7.4388765e-05]\n",
            " [9.9988055e-01]\n",
            " [9.9990404e-01]\n",
            " [8.8289198e-05]]\n",
            "모델의 예측값(Predicted): \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "실제값(Y): \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "정확도(Accuracy): \n",
            " 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 미니배치와 데이터 로더"
      ],
      "metadata": {
        "id": "-vhkcdmcpli8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n"
      ],
      "metadata": {
        "id": "95pam4hsplGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "232f6BILi7BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
        "from torch.utils.data import DataLoader # 데이터로더\n"
      ],
      "metadata": {
        "id": "FJRB1S5Zp4Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75],\n",
        "                               [93,  88,  93],\n",
        "                               [89,  91,  90],\n",
        "                               [96,  98,  100],\n",
        "                               [73,  66,  70]])\n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n"
      ],
      "metadata": {
        "id": "pnUDPz5_p5rY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(x_train, y_train)\n"
      ],
      "metadata": {
        "id": "t2iynywLp82g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n"
      ],
      "metadata": {
        "id": "8DjJpaMKp-SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(3,1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n"
      ],
      "metadata": {
        "id": "Os_v_GZtqAmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    # print(batch_idx)\n",
        "    # print(samples)\n",
        "    x_train, y_train = samples\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 계산\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
        "        cost.item()\n",
        "        ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgkmT4pyqDbv",
        "outputId": "c618a656-4b53-45f0-e4fb-79e5b351e7e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 Batch 1/3 Cost: 37679.203125\n",
            "Epoch    0/20 Batch 2/3 Cost: 15319.972656\n",
            "Epoch    0/20 Batch 3/3 Cost: 6793.727539\n",
            "Epoch    1/20 Batch 1/3 Cost: 1006.436768\n",
            "Epoch    1/20 Batch 2/3 Cost: 298.321472\n",
            "Epoch    1/20 Batch 3/3 Cost: 73.912346\n",
            "Epoch    2/20 Batch 1/3 Cost: 39.420811\n",
            "Epoch    2/20 Batch 2/3 Cost: 20.900702\n",
            "Epoch    2/20 Batch 3/3 Cost: 2.589400\n",
            "Epoch    3/20 Batch 1/3 Cost: 2.112917\n",
            "Epoch    3/20 Batch 2/3 Cost: 10.984287\n",
            "Epoch    3/20 Batch 3/3 Cost: 9.822260\n",
            "Epoch    4/20 Batch 1/3 Cost: 2.955473\n",
            "Epoch    4/20 Batch 2/3 Cost: 9.474287\n",
            "Epoch    4/20 Batch 3/3 Cost: 5.426064\n",
            "Epoch    5/20 Batch 1/3 Cost: 6.313222\n",
            "Epoch    5/20 Batch 2/3 Cost: 4.491042\n",
            "Epoch    5/20 Batch 3/3 Cost: 11.024273\n",
            "Epoch    6/20 Batch 1/3 Cost: 2.676070\n",
            "Epoch    6/20 Batch 2/3 Cost: 18.070728\n",
            "Epoch    6/20 Batch 3/3 Cost: 0.804834\n",
            "Epoch    7/20 Batch 1/3 Cost: 1.265853\n",
            "Epoch    7/20 Batch 2/3 Cost: 8.771469\n",
            "Epoch    7/20 Batch 3/3 Cost: 9.976078\n",
            "Epoch    8/20 Batch 1/3 Cost: 5.923325\n",
            "Epoch    8/20 Batch 2/3 Cost: 8.330780\n",
            "Epoch    8/20 Batch 3/3 Cost: 1.184868\n",
            "Epoch    9/20 Batch 1/3 Cost: 4.250082\n",
            "Epoch    9/20 Batch 2/3 Cost: 8.838964\n",
            "Epoch    9/20 Batch 3/3 Cost: 4.000916\n",
            "Epoch   10/20 Batch 1/3 Cost: 2.768124\n",
            "Epoch   10/20 Batch 2/3 Cost: 14.867640\n",
            "Epoch   10/20 Batch 3/3 Cost: 5.169767\n",
            "Epoch   11/20 Batch 1/3 Cost: 5.607749\n",
            "Epoch   11/20 Batch 2/3 Cost: 8.099838\n",
            "Epoch   11/20 Batch 3/3 Cost: 3.428397\n",
            "Epoch   12/20 Batch 1/3 Cost: 3.046112\n",
            "Epoch   12/20 Batch 2/3 Cost: 17.278355\n",
            "Epoch   12/20 Batch 3/3 Cost: 0.898237\n",
            "Epoch   13/20 Batch 1/3 Cost: 5.499949\n",
            "Epoch   13/20 Batch 2/3 Cost: 5.040722\n",
            "Epoch   13/20 Batch 3/3 Cost: 11.691274\n",
            "Epoch   14/20 Batch 1/3 Cost: 5.702143\n",
            "Epoch   14/20 Batch 2/3 Cost: 3.147292\n",
            "Epoch   14/20 Batch 3/3 Cost: 12.741139\n",
            "Epoch   15/20 Batch 1/3 Cost: 2.733077\n",
            "Epoch   15/20 Batch 2/3 Cost: 14.756037\n",
            "Epoch   15/20 Batch 3/3 Cost: 5.136307\n",
            "Epoch   16/20 Batch 1/3 Cost: 0.678827\n",
            "Epoch   16/20 Batch 2/3 Cost: 8.932206\n",
            "Epoch   16/20 Batch 3/3 Cost: 10.315118\n",
            "Epoch   17/20 Batch 1/3 Cost: 3.647161\n",
            "Epoch   17/20 Batch 2/3 Cost: 8.386954\n",
            "Epoch   17/20 Batch 3/3 Cost: 5.253018\n",
            "Epoch   18/20 Batch 1/3 Cost: 0.693897\n",
            "Epoch   18/20 Batch 2/3 Cost: 8.713689\n",
            "Epoch   18/20 Batch 3/3 Cost: 11.376107\n",
            "Epoch   19/20 Batch 1/3 Cost: 8.682295\n",
            "Epoch   19/20 Batch 2/3 Cost: 8.919033\n",
            "Epoch   19/20 Batch 3/3 Cost: 8.009255\n",
            "Epoch   20/20 Batch 1/3 Cost: 3.644725\n",
            "Epoch   20/20 Batch 2/3 Cost: 6.759336\n",
            "Epoch   20/20 Batch 3/3 Cost: 10.046180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OOAHa2Y1qGCn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}